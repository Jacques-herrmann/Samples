import './style.css'
import * as THREE from 'three'
import { OrbitControls } from 'three/examples/jsm/controls/OrbitControls.js'

/**
 * Textures
 * Textures are image that will cover the surface of the geometries, there are many types and effect you can create
 * with textures.
 *      1. Color Textures (or Albedo): Most simple one, apply on geometry
 *      2. Alpha Textures: Grayscale image, white is visible and black not
 *      3. Height Texture (Displacement): Grayscale image, move the vertices to create some relief (white go up and
 *         black down), need enough subdivision
 *      4. Normal Textures: use to add details (like height textures) and doesn't need subdivision because vertices
 *         won't move (-> better performances). Instead it lure the light about face orientation
 *      5. Ambient Occlusion: Also a grayscale image, this one add shadows in crevices (but not physically accurate).
 *         It helps to create contrast and details
 *      6. Metalness Textures: Grayscale image, white for metallic and black for non-metallic part. Helps to create
 *         reflexion
 *      7. Roughness Textures: Grayscale image, used in duo with metalness hte most of the time (white is rough and
 *         black is smooth). Used for light dissipation
 *      8. And many other types
 *
 * All this textures follow PBR (Physically Based Rendering) principles, especially the metalness and the roughness).
 * It's many technics that tend to follow real-life calculation.
 * Many software, engines and libraries fallowing those rules to get realistic results.
 * More here :
 *  - https://marmoset.co/posts/basic-theory-of-physically-based-rendering/
 *  - https://marmoset.co/posts/physically-based-rendering-and-you-can-too/
 *
 * 1. Access the texture file
 * By using webpack, we are two ways to do this :
 *  - Put the image inside the src folder and import it with javascript
 *      import imageSource from './image.jpg
 *  - Put the image inside the static folder and access it directly
 *      const image = '/image.jpg'
 *
 *
 * 2. Loading the image
 *  2.1 Using native Javascript:
 *
 * const image = new Image()
 * const texture = new THREE.Texture(image)// We cannot use this image directly, we need to convert it to Texture
 * image.onload = () => {
 *     texture.needsUpdate = true // Said to the texture that the image has changed
 * }
 * image.src = '/textures/door/color.jpg'
*/

/* 3. The LoadingManager
* Allow to mutualize the events, it's useful if we want to know the global loading progress or be informed when
* everything is loaded
* */
const loadingManager = new THREE.LoadingManager()
loadingManager.onStart = () => { console.log('start') }
loadingManager.onLoad = () => { console.log('load') }
loadingManager.onProgress = () => { console.log('progress') }
loadingManager.onError = () => { console.log('error') }

/* 2.2 Using TextureLoader */
const textureLoader = new THREE.TextureLoader(loadingManager)
// const colorTexture = textureLoader.load(
//     '/textures/door/color.jpg',
//     // () => { console.log('load') }, // when the image loaded successfully
//     // () => { console.log('progress') }, // when the loading is progressing
//     // () => { console.log('error') }, // if something went wrong
// ) // One TextureLoader can load multiple image !
// const colorTexture = textureLoader.load("/textures/checkerboard-1024x1024.png")//moirÃ© pattern test for Minification Filter
// const colorTexture = textureLoader.load("/textures/checkerboard-8x8.png")// Magnification Filter
const colorTexture = textureLoader.load("/textures/minecraft.png")// Magnification Filter
const alphaTexture = textureLoader.load("/textures/door/alpha.jpg")
const heightTexture = textureLoader.load("/textures/door/height.jpg")
const normalTexture = textureLoader.load("/textures/door/normal.jpg")
const ambientOcclusionTexture = textureLoader.load("/textures/door/ambientOcclusion.jpg")
const metalnessTexture = textureLoader.load("/textures/door/metalness.jpg")
const roughnessTexture = textureLoader.load("/textures/door/roughness.jpg")

/* 4. UV Unwrapping
* The texture is being stretched or squeezed in different ways to cover the geometry. This is called UV unwrapping and
* it's like unwrapping an origami or a candy wrap to maje it flat. Each vertex will have 2D coordinate on a flat plane
* (usually a square).
* It's possible to see those UV coordinates in geometry.attributes.uv, they are generated by Three.js.
* If you create your own geometry or making the geometry using a 3D software, you'll have to specify the UV coordinates
*/

/* 5. Transforming the Texture
*    5.1 Repeat the texture */
// colorTexture.repeat.x = 2
// colorTexture.repeat.y = 3

// At this point you will see that the texture has the good size put are not repeating, the last pixel get stretched.
// To fix that we have to set the wrapS and wrapT property to RepeatWrapping
// colorTexture.wrapS = THREE.RepeatWrapping
// colorTexture.wrapT = THREE.RepeatWrapping
// You can alternate the direction using MirroredRepeatWrapping

/*  5.2 Offset */
// colorTexture.offset.x = 2
// colorTexture.offset.y = 3

/*  5.3 Rotation (2D space) */
// colorTexture.rotation = Math.PI * 0.25 // The rotation occurs by default on the 0, 0 uv point
// colorTexture.center.x = 0.5 // Move the rotation center to 0.5, 0.5
// colorTexture.center.y = 0.5

/* 6. Filtering and MipMapping
* MipMapping is a technic that consists of creating half a smaller version of a texture again and again until we get
* a 1x1 texture. All those texture variations are sent to the GPU, and the GPU will choose the most appropriate version
* of the texture to display.
* All of this is already handled bu Three.js and the GPU but wa can choose different algorithms :
*       1. Minification Filter: Happens when the pixels of the texture are smaller than the pixels of the render
*          (texture size > render size). There are 6 possible values (NearestFilter, LinearFilter,
*           NearestMipmapNearestFilter, NearestMipmapLinearFilter, LinearMipmapNearestFilter, LinearMipmapLinearFilter)
* */

// When using the NearFilter on minFilter, we don't need the mipmaps. We can deactivates the mipmaps generation with
colorTexture.generateMipmaps = false
colorTexture.minFilter = THREE.NearestFilter

/*      2. Magnification Filter: Happens when the pixels of the textures are bigger than the pixels of the render
*          (texture size < render size). There are 2 possible value (NearestFilter, LinearFilter)
* */
colorTexture.magFilter = THREE.NearestFilter // Better for performances

/* 7. Texture Format and Optimization
* When preparing your texture, keep in mind 3 crucial elements:
*       1. The weight of the file: .jpg lossy compression but usually lighter, .png is lossless compression but usually
*           heavier (You can compress it with TinyPNG or Basis)
*       2. The size (resolution): Each pixel of the textures will have to be stored on the GPU regardless of the image's
*          weight. GPU has storage limitations. It's event worse because mipmapping increase the number of pixels to
*          store. Try to reduce the size of your images.
*          !!! The texture width and height must be a power of 2, unless the mipmapping will not work
*       3. The data: Textures support transparency but can't have transparency in .jpg.
*          If we want to have only one texture that combine color and alpha, we better use .png file.
*          If you use a normal texture, we want to have the exact values which is why it's better to use .png (no lossy
*          compression)
*          You can combine different data into one texture by using the red, green, blue and alpha channels seperatly
*
* The difficulty is to find the right combination of texture formats and resolutions.
*
* 8. Where to find textures
*       - poliigon.com
*       - 3dtextures.me
*       - arroway-textures.ch
*       - Substance Designer (software)
*
* */
// Canvas
const canvas = document.querySelector('canvas.webgl')

// Scene
const scene = new THREE.Scene()

/**
 * 3. Use the texture on material
 * Only replace the color property by the property map: texture
 */
const geometry = new THREE.BoxGeometry(1, 1, 1)
const material = new THREE.MeshBasicMaterial({ map: colorTexture })
const mesh = new THREE.Mesh(geometry, material)
scene.add(mesh)

/**
 * Sizes
 */
const sizes = {
    width: window.innerWidth,
    height: window.innerHeight
}

window.addEventListener('resize', () =>
{
    // Update sizes
    sizes.width = window.innerWidth
    sizes.height = window.innerHeight

    // Update camera
    camera.aspect = sizes.width / sizes.height
    camera.updateProjectionMatrix()

    // Update renderer
    renderer.setSize(sizes.width, sizes.height)
    renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2))
})

/**
 * Camera
 */
// Base camera
const camera = new THREE.PerspectiveCamera(75, sizes.width / sizes.height, 0.1, 100)
camera.position.x = 1
camera.position.y = 1
camera.position.z = 1
scene.add(camera)

// Controls
const controls = new OrbitControls(camera, canvas)
controls.enableDamping = true

/**
 * Renderer
 */
const renderer = new THREE.WebGLRenderer({
    canvas: canvas
})
renderer.setSize(sizes.width, sizes.height)
renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2))

/**
 * Animate
 */
const clock = new THREE.Clock()

const tick = () =>
{
    const elapsedTime = clock.getElapsedTime()

    // Update controls
    controls.update()

    // Render
    renderer.render(scene, camera)

    // Call tick again on the next frame
    window.requestAnimationFrame(tick)
}

tick()